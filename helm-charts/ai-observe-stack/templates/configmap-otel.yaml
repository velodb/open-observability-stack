{{/*
OpenTelemetry Collector Configuration ConfigMap
*/}}
{{- if .Values.otel.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "aiobs.otel.fullname" . }}-config
  labels:
    {{- include "aiobs.labels" . | nindent 4 }}
    app.kubernetes.io/component: otel-collector
data:
  config.yaml: |
    # OpenTelemetry Collector Configuration
    # Generated by AIObserve Stack Helm Chart

    receivers:
      # OTLP receiver - standard protocol for traces, metrics, and logs
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:{{ .Values.otel.ports.otlpGrpc }}
          http:
            endpoint: 0.0.0.0:{{ .Values.otel.ports.otlpHttp }}

      {{- if and .Values.otel.selfMonitoring.enabled .Values.otel.selfMonitoring.hostmetrics.enabled }}
      # ============================================================================
      # Self-Observability Receivers - Generate metrics from the collector itself
      # ============================================================================

      # Host metrics receiver - collects system metrics (CPU, memory, disk, network)
      hostmetrics:
        collection_interval: {{ .Values.otel.selfMonitoring.hostmetrics.collectionInterval }}
        scrapers:
          {{- if .Values.otel.selfMonitoring.hostmetrics.scrapers.cpu }}
          cpu:
            metrics:
              system.cpu.utilization:
                enabled: true
          {{- end }}
          {{- if .Values.otel.selfMonitoring.hostmetrics.scrapers.memory }}
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
          {{- end }}
          {{- if .Values.otel.selfMonitoring.hostmetrics.scrapers.disk }}
          disk:
          {{- end }}
          {{- if .Values.otel.selfMonitoring.hostmetrics.scrapers.filesystem }}
          filesystem:
          {{- end }}
          {{- if .Values.otel.selfMonitoring.hostmetrics.scrapers.network }}
          network:
          {{- end }}
          {{- if .Values.otel.selfMonitoring.hostmetrics.scrapers.load }}
          load:
          {{- end }}
          {{- if .Values.otel.selfMonitoring.hostmetrics.scrapers.processes }}
          processes:
          {{- end }}
      {{- end }}

      {{- if and .Values.otel.selfMonitoring.enabled .Values.otel.selfMonitoring.prometheus.enabled }}
      # Prometheus receiver - scrape collector's own metrics from metrics port
      prometheus:
        config:
          scrape_configs:
            - job_name: {{ .Values.otel.selfMonitoring.prometheus.jobName | quote }}
              scrape_interval: {{ .Values.otel.selfMonitoring.prometheus.scrapeInterval }}
              static_configs:
                - targets: ['localhost:{{ .Values.otel.ports.metrics }}']
                  labels:
                    {{- range $key, $value := .Values.otel.selfMonitoring.prometheus.labels }}
                    {{ $key }}: {{ $value | quote }}
                    {{- end }}
      {{- end }}

    processors:
      # Batch processor - batches data before sending to exporters
      batch:
        timeout: {{ .Values.otel.batch.timeout }}
        send_batch_size: {{ .Values.otel.batch.sendBatchSize }}
        send_batch_max_size: {{ .Values.otel.batch.sendBatchMaxSize }}

      # Memory limiter - prevents OOM
      memory_limiter:
        check_interval: {{ .Values.otel.memoryLimiter.checkInterval }}
        limit_mib: {{ .Values.otel.memoryLimiter.limitMib }}
        spike_limit_mib: {{ .Values.otel.memoryLimiter.spikeLimitMib }}

    exporters:
      # Doris exporter - single exporter for traces, logs, and metrics
      doris:
        endpoint: {{ include "aiobs.doris.feHttpEndpoint" . }}
        database: {{ include "aiobs.doris.database" . }}
        username: {{ include "aiobs.doris.user" . }}
        password: "{{ include "aiobs.doris.password" . }}"
        create_schema: true
        mysql_endpoint: {{ include "aiobs.doris.mysqlEndpoint" . }}
        table:
          logs: {{ .Values.otel.dorisExporter.tables.logs }}
          traces: {{ .Values.otel.dorisExporter.tables.traces }}
          metrics: {{ .Values.otel.dorisExporter.tables.metrics }}
        history_days: {{ .Values.otel.dorisExporter.historyDays }}
        create_history_days: {{ .Values.otel.dorisExporter.createHistoryDays }}
        replication_num: {{ .Values.otel.dorisExporter.replicationNum }}
        timezone: {{ .Values.openObservabilityStack.timezone }}
        log_response: false
        timeout: {{ .Values.otel.dorisExporter.timeout }}
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s
        {{- with .Values.otel.dorisExporter.sendingQueue }}
        sending_queue:
          enabled: {{ .enabled }}
          num_consumers: {{ .numConsumers }}
          queue_size: {{ .queueSize }}
        {{- end }}

      {{- if .Values.otel.debug.enabled }}
      # Debug exporter for troubleshooting
      debug:
        verbosity: {{ .Values.otel.debug.verbosity }}
        sampling_initial: 5
        sampling_thereafter: 200
      {{- end }}

    extensions:
      # Health check extension
      health_check:
        endpoint: 0.0.0.0:{{ .Values.otel.ports.healthCheck }}
        path: "/"
        check_collector_pipeline:
          enabled: true
          interval: "5m"
          exporter_failure_threshold: 5

      # Performance profiler
      pprof:
        endpoint: 0.0.0.0:1777

      # zPages for debugging
      zpages:
        endpoint: 0.0.0.0:55679

    service:
      extensions: [health_check, pprof, zpages]

      telemetry:
        logs:
          level: {{ .Values.otel.logging.level | default "info" }}
          encoding: {{ .Values.otel.logging.format | default "json" }}
          {{- if and .Values.otel.persistence.enabled .Values.otel.logging.fileOutput.enabled }}
          # Output logs to file for persistence and tracking
          output_paths:
            - stdout
            - {{ .Values.otel.persistence.logPath }}/collector.log
          error_output_paths:
            - stderr
            - {{ .Values.otel.persistence.logPath }}/collector-error.log
          {{- end }}
          # Add pod identity to logs for tracking in multi-replica setup
          initial_fields:
            service: otel-collector
        metrics:
          level: detailed
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: "0.0.0.0"
                    port: {{ .Values.otel.ports.metrics }}

      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters:
            - doris
            {{- if .Values.otel.debug.enabled }}
            - debug
            {{- end }}

        metrics:
          receivers:
            - otlp
            {{- if and .Values.otel.selfMonitoring.enabled .Values.otel.selfMonitoring.hostmetrics.enabled }}
            - hostmetrics
            {{- end }}
            {{- if and .Values.otel.selfMonitoring.enabled .Values.otel.selfMonitoring.prometheus.enabled }}
            - prometheus
            {{- end }}
          processors: [memory_limiter, batch]
          exporters:
            - doris
            {{- if .Values.otel.debug.enabled }}
            - debug
            {{- end }}

        logs:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters:
            - doris
            {{- if .Values.otel.debug.enabled }}
            - debug
            {{- end }}
{{- end }}
